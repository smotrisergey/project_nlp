{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d4a020-6d56-4089-bb3c-9e204f26010f",
   "metadata": {},
   "source": [
    "# WCC Implementation, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db9eeb0-cd51-41de-bdcb-0297cf4a3af4",
   "metadata": {},
   "source": [
    "!pip install -q stanza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d543f7-f166-4e71-bc95-dccc0341ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f2227-3728-46ef-852e-826341f4dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Skylion007/openwebtext\", split=\"train\", streaming=True)\n",
    "\n",
    "def get_batch(dataset, batch_size):\n",
    "    batch = []\n",
    "    for i, example in enumerate(dataset):\n",
    "        batch.append(example)\n",
    "        if i + 1 == batch_size:\n",
    "            break\n",
    "    return batch\n",
    "\n",
    "\n",
    "batch_size = 5_000_000\n",
    "batch = get_batch(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d093ae-ca70-443d-83c5-21a8dbaebef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download(\"en\")\n",
    "nlp = stanza.Pipeline('ru', processors='tokenize', use_gpu=True)\n",
    "\n",
    "\n",
    "def split_into_sentences(paragraph):\n",
    "    doc = nlp(paragraph)\n",
    "    sentences = [sentence.text for sentence in doc.sentences]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def count_words(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "\n",
    "paragraphs = batch\n",
    "\n",
    "data = []\n",
    "\n",
    "for paragraph_id, paragraph in enumerate(tqdm(paragraphs), start=1):\n",
    "    sentences = split_into_sentences(paragraph['text'])\n",
    "    for sentence in sentences:\n",
    "        word_count = count_words(sentence)\n",
    "        data.append([sentence, word_count, paragraph_id])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Sentence', 'Word Count', 'Paragraph ID'])\n",
    "\n",
    "\n",
    "output_path = 'sentences.csv'\n",
    "df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
